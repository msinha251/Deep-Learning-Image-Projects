{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SimplePreprocessor:\n",
    "import cv2\n",
    "class SimplePreprocessor():\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "    def proprocess(self, image):\n",
    "        #resizing the image to the fixed width and height ignoring the aspect ratio\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SimpleDatasetLoader:\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "class SimpleDatasetLoader():\n",
    "    def __init__(self, preprocessors = None):\n",
    "        self.preprocessors = preprocessors\n",
    "        \n",
    "        #if preprocessors are None, initialize them as an empty list:\n",
    "        if self.preprocessors == None:\n",
    "            self.preprocessors = []\n",
    "        \n",
    "    def load(self, imagePaths, verbose=-1):\n",
    "        #initialize the list of features and labels:\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        #loop over the input image:\n",
    "        for i, imagePath, in enumerate(imagePaths):\n",
    "            #load an image and extract the class labels assuming that..\n",
    "            #our path has following format: /path/to/dataset/{class}/{image}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = imagePath.split('/')[-2]\n",
    "            \n",
    "            #check to see if the preprocessors is not None:\n",
    "            if self.preprocessors is not None:\n",
    "                #loop over each preprocessors and apply each to the image:\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.proprocess(image)\n",
    "            #treat out preprocessed image as \"feature vector\" \n",
    "            #by updating the data list followed by the labels:\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            if verbose>0 and i>0 and (i+1)%verbose==0:\n",
    "                print(f'[INFO] processed {i+1}/{len(imagePaths)}')\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/3000\n",
      "[INFO] processed 1000/3000\n",
      "[INFO] processed 1500/3000\n",
      "[INFO] processed 2000/3000\n",
      "[INFO] processed 2500/3000\n",
      "[INFO] processed 3000/3000\n",
      "[INFO] features matrix: 9.0MB\n"
     ]
    }
   ],
   "source": [
    "#Train k-nn:\n",
    "\n",
    "#Step 1: collect dataset:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "#import argparse\n",
    "\n",
    "#grab the list of images:\n",
    "print('[INFO] loading images...')\n",
    "imagePaths = [i.replace('\\\\', '/') for i in list(paths.list_images('animals/'))]\n",
    "\n",
    "#initialize the image preprocessor and load the datasets from the disk\n",
    "# and reshapes the data matrix:\n",
    "sp = SimplePreprocessor(32,32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "#show some information on memory consumption on images:\n",
    "print(f'[INFO] features matrix: {data.nbytes/(1024*1000.0)}MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Split datasets:\n",
    "#encode the labesl as an intiger from strings:\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "#splitting the data into training and testing by 75% and 25%:\n",
    "trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating k-NN classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.42      0.61      0.50       262\n",
      "        dogs       0.39      0.47      0.42       249\n",
      "       panda       0.91      0.27      0.41       239\n",
      "\n",
      "    accuracy                           0.45       750\n",
      "   macro avg       0.57      0.45      0.44       750\n",
      "weighted avg       0.57      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Train and evaluate classifier:\n",
    "print('[INFO] evaluating k-NN classifier...')\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(trainX, trainY)\n",
    "print(classification_report(testY, model.predict(testX), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.42      0.61      0.50       262\n",
      "        dogs       0.39      0.47      0.42       249\n",
      "       panda       0.91      0.27      0.41       239\n",
      "\n",
      "    accuracy                           0.45       750\n",
      "   macro avg       0.57      0.45      0.44       750\n",
      "weighted avg       0.57      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cats', 'dogs', 'panda'], dtype='<U5')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
